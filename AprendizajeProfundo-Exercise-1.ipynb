{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Universidad Nacional de Córdoba\n",
    "# DIPLODATOS - Facultad de Matemática, Astronomía, Física y Computación\n",
    "\n",
    "## Trabajo Práctico Número 1 (Analisis del archivo exercise_1.py)\n",
    "\n",
    "Autores: \n",
    "* Diaz Cobos Facundo\n",
    "* Epifanio Luis\n",
    "* Gonzalez Leonardo David\n",
    "* Gualpa Mariano Martín\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Consigna del Ejercicio 1.\n",
    "\n",
    "1. Procesar el conjunto de datos para obtener una representación TfIDf de cada review.\n",
    "  * Hint: User el código de *Aprendizaje Supervisado*\n",
    "  * Hint: El método de fit de Keras crea internamente un conjunto de datos de validación, por lo que no tienen que preocuparse por eso.\n",
    "\n",
    "2. Construir un pipeline de clasificación con un modelo Keras MLP.\n",
    "\n",
    "3. Entrenar uno o varios modelos (con dos o tres es suficiente, veremos más de esto en el práctico 2). Evaluar los modelos en el conjunto de test.\n",
    "\n",
    "4. Reportar los hyperparámetros y resultados de todos los modelos entrenados. Para esto, pueden utilizar una notebook o un archivo (pdf|md). Dentro de este reporte tiene que describir:\n",
    "  * Hyperparámetros con los que procesaron el dataset: tamaño del vocabulario, normalizaciones, etc.\n",
    "  * Las decisiones tomadas al construir cada modelo: regularización, dropout, número y tamaño de las capas, optimizador.\n",
    "  * Proceso de entrenamiento: división del train/test, tamaño del batch, número de épocas, métricas de evaluación. Seleccione los mejores hiperparámetros en función de su rendimiento. El proceso de entrenamiento debería ser el mismo para todos los modelos.\n",
    "  * (Punto estrella) Analizar si el clasificador está haciendo overfitting. Esto se puede determinar a partir del resultado del método fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Desarrollo.\n",
    "\n",
    "## 2.1. Carga de Librerías y Funciones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T03:45:02.949218Z",
     "start_time": "2018-09-22T03:45:02.936300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.auto_scroll_threshold = 9999;"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.auto_scroll_threshold = 9999;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T03:45:04.613427Z",
     "start_time": "2018-09-22T03:45:02.951091Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mgualpa/anaconda3/envs/DataScience/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1\n",
    "import argparse\n",
    "import pandas\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "from keras.models import Sequential\n",
    "from tensorflow.python.keras.utils import np_utils   # for tf 1.3.1\n",
    "#from tensorflow.python.keras import utils as np_utils     # for tf 1.4.1\n",
    "\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.model_selection import train_test_split\n",
    "from itertools import repeat\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from printutils import print_message, print_new_process, print_end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T03:45:04.637078Z",
     "start_time": "2018-09-22T03:45:04.616162Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_args():\n",
    "    parser = argparse.ArgumentParser(description='Exercise 1')\n",
    "    # Here you have some examples of classifier parameters. You can add\n",
    "    # more arguments or change these if you need to.\n",
    "    parser.add_argument('--num_units', nargs='+', default=[100], type=int,\n",
    "                        help='Number of hidden units of each hidden layer.')\n",
    "    parser.add_argument('--dropout', nargs='+', default=[0.5], type=float,\n",
    "                        help='Dropout ratio for every layer.')\n",
    "    parser.add_argument('--batch_size', type=int, default=32,\n",
    "                        help='Number of instances in each batch.')\n",
    "\n",
    "    # New parameters:    \n",
    "    parser.add_argument('--model', type=int, default=10, help='Number of model to run')\n",
    "    parser.add_argument('--max_features', type=int, default=2000, help='Max number of words used inTfidfVectorizer')\n",
    "    parser.add_argument('--epochs', type=int, default=10, help='Number of epochs')\n",
    "    parser.add_argument('--shuffle', type=str, default='batch', help='Shuffle value')\n",
    "    parser.add_argument('--random_seed', type=int, default=10, help='Random seed number')\n",
    "    parser.add_argument('--verbose', type=int, default=1, help='Verbose info on screen')\n",
    "    \n",
    "    # parse parameters\n",
    "    if arguments == None:\n",
    "        args = parser.parse_args()\n",
    "    else:\n",
    "        args = parser.parse_args(arguments)\n",
    "\n",
    "    assert len(args.num_units) == len(args.dropout)\n",
    "    return args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Procesar el conjunto de datos utilizando TfIDf vectorizer para crear una matriz de entrada.\n",
    "\n",
    "__Responde al punto:__\n",
    "\n",
    "_1. Procesar el conjunto de datos para obtener una representación TfIDf de cada review._\n",
    "  * _Hint: User el código de *Aprendizaje Supervisado*_\n",
    "  * _Hint: El método de fit de Keras crea internamente un conjunto de datos de validación, por lo que no tienen que preocuparse por eso._\n",
    "\n",
    "\n",
    "### Apply the Tfidf vectorizer to create input matrix\n",
    "Creamos un método para vectorizar la entrada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T03:45:04.661331Z",
     "start_time": "2018-09-22T03:45:04.639663Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    \n",
    "# TODO 1: Apply the Tfidf vectorizer to create input matrix\n",
    "def vectorize_input(x_train, x_test, args):\n",
    "\n",
    "    # vectorizer = TfidfVectorizer(analyzer='word', use_idf=True, max_features=args.max_features) # Original\n",
    "    vectorizer = TfidfVectorizer(binary=False, max_df=0.1, min_df=5, ngram_range=(1, 4), max_features=args.max_features)\n",
    "    \n",
    "    x_train_vec = vectorizer.fit_transform(x_train).toarray()\n",
    "    print_message('x_train_vec - type: {}, shape:{}'.format(type(x_train_vec),x_train_vec.shape),args)\n",
    "    \n",
    "    #x_test_vec = vectorizer.fit_transform(x_test).toarray()\n",
    "    x_test_vec = vectorizer.transform(x_test).toarray()\n",
    "\n",
    "    print_message('x_test_vec - type: {}, shape:{}'.format(type(x_test_vec),x_test_vec.shape),args)\n",
    "      \n",
    "    return x_train_vec, x_test_vec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funcion: load_dataset():         \n",
    "La misma función del archivo, donde llamamos a nuestra nueva rutina:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T03:45:04.677576Z",
     "start_time": "2018-09-22T03:45:04.664435Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "\n",
    "def load_dataset(args):\n",
    "    \n",
    "    print_new_process('Load and vectorize Data:',args)\n",
    "    \n",
    "    dataset = load_files('dataset/txt_sentoken', shuffle=False)\n",
    "\n",
    "    #(X_train, X_test), (y_train, y_test) = imdb.load_data()\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(dataset.data, dataset.target, test_size=0.25, random_state=10042)\n",
    "    \n",
    "    print_message('Training samples {} ({}), test_samples {} ({})'.format(\n",
    "        len(X_train),\n",
    "        len(y_train), \n",
    "        len(X_test), \n",
    "        len(y_test)), args)\n",
    "\n",
    "    # TODO 1: Apply the Tfidf vectorizer to create input matrix\n",
    "    x_train_vec, x_test_vec = vectorize_input(X_train, X_test,args)\n",
    "        \n",
    "    return x_train_vec, x_test_vec, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Construir modelos Keras\n",
    "\n",
    "Se plantean modelos con diferentes arquitecturas para realizar las pruebas:\n",
    "\n",
    "### Build the Keras models:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T04:07:56.486348Z",
     "start_time": "2018-09-22T04:07:56.470725Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Activation, Dropout, Embedding, LSTM\n",
    "from keras import optimizers, regularizers\n",
    "\n",
    "def build_keras_model_1(x_train_vec, args):\n",
    "    \n",
    "    input_size = x_train_vec.shape[1]\n",
    "    num_units = args.num_units[0]   \n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    #model.add(Dense(1, activation = 'sigmoid', input_shape=(input_size,)))\n",
    "\n",
    "    model.add(Dense(num_units, activation='relu', input_shape=(input_size,)))\n",
    "    \n",
    "    model.add(Dropout(args.dropout[0]))    \n",
    "    \n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', \n",
    "                  optimizer='adam', \n",
    "                  metrics=['binary_accuracy'])\n",
    "    \n",
    "    # Show model info on screen\n",
    "    print_message('MODEL 1:', args )\n",
    "    print_message( model.summary(), args )\n",
    "\n",
    "    \"\"\"\n",
    "    input_size = x_train_vec.shape[1]\n",
    "       \n",
    "    model = Sequential()\n",
    "    model.add(Dense( args.num_units[0], input_shape=(input_size,)))    \n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dropout(args.dropout[0]))    \n",
    "    \n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer=optimizers.Adagrad(), \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # Show model info on screen\n",
    "    print_message('MODEL 1:', args )\n",
    "    print_message( model.summary(), args )\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T03:48:21.412996Z",
     "start_time": "2018-09-22T03:48:21.315513Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\ndef build_keras_model_2(x_train_vec, args):\\n    \\n    input_size = x_train_vec.shape[1]\\n       \\n    model = Sequential()\\n\\n    model.add(Dense(input_size, input_dim=input_size, kernel_initializer='normal', activation='relu'))\\n    model.add(Dropout(args.dropout[0]))\\n    model.add(Dense(int(input_size/2), kernel_initializer='normal', activation='relu'))\\n    model.add(Dropout(args.dropout[0]))\\n    model.add(Dense(int(input_size), kernel_initializer='normal', activation='relu'))\\n    model.add(Dropout(args.dropout[0]))\\n    model.add(Dense(int(input_size/2), kernel_initializer='normal', activation='relu'))\\n    model.add(Dropout(args.dropout[0]))\\n    model.add(Dense(2, kernel_initializer='normal', activation='sigmoid'))\\n    \\n    model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])\\n    \\n    # Show model info on screen\\n    print_message('MODEL 2:', args )\\n    print_message( model.summary(), args )\\n\\n    return model\\n    \\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_keras_model_2(x_train_vec, args):\n",
    "    \n",
    "    input_size = x_train_vec.shape[1]\n",
    "       \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(input_size, kernel_regularizer=regularizers.l1(0.001), activation='relu', input_shape=(input_size,)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(16, kernel_regularizer=regularizers.l1(0.001),activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Use of REGULARIZATION\n",
    "    #model = models.Sequential()\n",
    "    #model.add(Dense(16, kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.001),activation='relu', input_shape=(10000,)))\n",
    "    #model.add(Dense(16, kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.001),activation='relu'))\n",
    "    #model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # REGULARIZERS L1 L2\n",
    "    #regularizers.l1(0.001)\n",
    "    #regularizers.l2(0.001)\n",
    "    #regularizers.l1_l2(l1=0.001, l2=0.001)\n",
    "    \n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    # Show model info on screen\n",
    "    print_message('MODEL 2:', args )\n",
    "    print_message( model.summary(), args )\n",
    "\n",
    "    return model\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def build_keras_model_2(x_train_vec, args):\n",
    "    \n",
    "    input_size = x_train_vec.shape[1]\n",
    "       \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(input_size, input_dim=input_size, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dropout(args.dropout[0]))\n",
    "    model.add(Dense(int(input_size/2), kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dropout(args.dropout[0]))\n",
    "    model.add(Dense(int(input_size), kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dropout(args.dropout[0]))\n",
    "    model.add(Dense(int(input_size/2), kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dropout(args.dropout[0]))\n",
    "    model.add(Dense(2, kernel_initializer='normal', activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    # Show model info on screen\n",
    "    print_message('MODEL 2:', args )\n",
    "    print_message( model.summary(), args )\n",
    "\n",
    "    return model\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T04:09:04.415521Z",
     "start_time": "2018-09-22T04:09:04.388283Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_keras_model_3(x_train_vec, args):\n",
    "    \n",
    "    input_size = x_train_vec.shape[1]\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_size, args.num_units[0], input_shape=(input_size,)))\n",
    "    model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Dense(2, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "    # Show model info on screen\n",
    "    print_message('MODEL 3:', args )\n",
    "    print_message( model.summary(), args )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Activation, Dropout, Embedding, LSTM, Flatten\n",
    "\n",
    "def build_keras_model_4(x_train_vec, args):\n",
    " \n",
    "    input_size = x_train_vec.shape[1]\n",
    "       \n",
    "    model = Sequential()\n",
    "    model.add(Dense(args.num_units[0], input_shape=(input_size,)))    \n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dropout(args.dropout[0]))    \n",
    "    \n",
    "    model.add(Dense( int(input_size/2) ))    \n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dropout(args.dropout[0]))       \n",
    "\n",
    "    model.add(Dense( int(input_size/4) ))    \n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dropout(args.dropout[0]))\n",
    "    \n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer=optimizers.Adagrad(), \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # Show model info on screen\n",
    "    print_message('MODEL 4:', args )\n",
    "    print_message( model.summary(), args )\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Entrenamiento del Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.1. Main:\n",
    "\n",
    "Función principal que llama a las rutinas anteriores para realizar el entrenamiento. \n",
    "\n",
    "__Responde al punto:__\n",
    "\n",
    "_2. Construir un pipeline de clasificación con un modelo Keras MLP._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T03:45:04.854652Z",
     "start_time": "2018-09-22T03:45:04.743319Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "def main():\n",
    "\n",
    "    USE_CATEGORICAL = False\n",
    "    \n",
    "    experiment_number = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    \n",
    "    args = read_args()\n",
    "    \n",
    "    print_new_process('START:', args)\n",
    "    \n",
    "    # Configuramos la semilla aleatoria por reproducibilidad\n",
    "    np.random.seed(args.random_seed)\n",
    "    \n",
    "    # Cargamos el dataset\n",
    "    x_train_vec, x_test_vec, y_train, y_test_orginal = load_dataset(args)\n",
    "\n",
    "    # TODO 2: Convert the labels to categorical\n",
    "    if (USE_CATEGORICAL):\n",
    "        num_classes = 2 \n",
    "        #y_train_cat = np_utils.to_categorical(y_train, num_classes)    \n",
    "        #y_test_cat = np_utils.to_categorical(y_test_orginal, num_classes)    \n",
    "        y_train_cat = to_categorical(y_train)    \n",
    "        y_test_cat = to_categorical(y_test_orginal)    \n",
    "\n",
    "    else:\n",
    "        y_train_cat = y_train    \n",
    "        y_test_cat = y_test_orginal    \n",
    "\n",
    "    \n",
    "    \n",
    "    print_new_process('Build Model:', args )\n",
    "    # TODO 3: Build the Keras model\n",
    "    switcher = {\n",
    "        1: build_keras_model_1,\n",
    "        2: build_keras_model_2,\n",
    "        3: build_keras_model_3,\n",
    "        4: build_keras_model_4,\n",
    "    }\n",
    "    # Get the function from switcher dictionary\n",
    "    model_builder = switcher.get(args.model, lambda: \"nothing\")\n",
    "    \n",
    "    model = model_builder(x_train_vec, args)\n",
    "    \n",
    "    # TODO 4: Fit the model    \n",
    "    print_new_process('Fit:', args)\n",
    "    history = model.fit(x_train_vec, y_train_cat,\n",
    "                        batch_size=args.batch_size,\n",
    "                        epochs=args.epochs,\n",
    "                        shuffle=args.shuffle,\n",
    "                        verbose=1,\n",
    "                        validation_split=0.70\n",
    "             )\n",
    "\n",
    "    # TODO 5: Evaluate the model, calculating the metrics.\n",
    "    # Option 1: Use the model.evaluate() method. For this, the model must be\n",
    "    # already compiled with the metrics.\n",
    "    print_new_process('Predictions:',args)\n",
    "    predictions = history.model.predict_classes(x_test_vec, verbose=1)\n",
    "    \n",
    "    if args.verbose == 1:\n",
    "        display(str(list( predictions)))\n",
    "\n",
    "    print_new_process('Test:',args)\n",
    "    if args.verbose == 1:        \n",
    "        display(str(list(y_test_orginal)))\n",
    "    \n",
    "    print_new_process('Performance:',args)\n",
    "    score, accuracy = history.model.evaluate(x_test_vec, y_test_cat)\n",
    "    #score, accuracy = model.evaluate(x_train_vec, y_train_cat)\n",
    "\n",
    "    print_message('[score, accuracy]', args)\n",
    "    print_message([score, accuracy], args)\n",
    "\n",
    "    # Option 2: Use the model.predict() method and calculate the metrics using\n",
    "    # sklearn. We recommend this, because you can store the predictions if\n",
    "    # you need more analysis later. Also, if you calculate the metrics on a\n",
    "    # notebook, then you can compare multiple classifiers.\n",
    "    # predictions = ...\n",
    "    # performance = ...\n",
    "\n",
    "    # TODO 6: Save the results.    \n",
    "    parameters_path = 'results/parameters/'\n",
    "    if not os.path.exists(parameters_path):\n",
    "        os.makedirs(parameters_path)\n",
    "    predictions_path = 'results/predictions/'\n",
    "    if not os.path.exists(predictions_path):\n",
    "        os.makedirs(predictions_path)\n",
    "\n",
    "    parameters_filename = 'results/parameters/parameters_{0}_acc_{1:.6f}.csv'.format(experiment_number, accuracy)\n",
    "    print_new_process('Saving parameters: {}'.format(parameters_filename),args)  \n",
    "    \n",
    "    parameters_df = pandas.DataFrame(columns=['Parameter','Value'])\n",
    "    for k,v in sorted(vars(args).items()):\n",
    "        row = pandas.Series([str(k), str(v)], index=['Parameter', 'Value'])\n",
    "        parameters_df = parameters_df.append(row,ignore_index=True)\n",
    "    parameters_df.to_csv(parameters_filename, index=False )\n",
    "    \n",
    "    predictions_filename = 'results/predictions/predictions_{0}_acc_{1:.6f}.csv'.format(experiment_number, accuracy)\n",
    "    print_new_process('Saving predictions: {}'.format(predictions_filename),args)  \n",
    "    predictions_df = pandas.DataFrame(y_test_orginal, columns=['true_label'])\n",
    "    predictions_df.loc[:, 'predicted'] = predictions\n",
    "    predictions_df.to_csv(predictions_filename, index=False)\n",
    "    \n",
    "    print_message('Done.',args)    \n",
    "    print_end('STOP.',args)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.2. Ejecución del modelo:\n",
    "\n",
    "__Responde al punto:__\n",
    "\n",
    "_3. Entrenar uno o varios modelos (con dos o tres es suficiente, veremos más de esto en el práctico 2). Evaluar los modelos en el conjunto de test._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false
   },
   "source": [
    "Ejecutamos una prueba de main para poder visualizar que el funcionamiento sea adecuado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-10 22:00:44 ------------------------------------------------------------------------\n",
      "2018-12-10 22:00:44 - START:\n",
      "2018-12-10 22:00:44 ------------------------------------------------------------------------\n",
      "2018-12-10 22:00:44 - Load and vectorize Data:\n",
      "2018-12-10 22:00:57 - Training samples 1500 (1500), test_samples 500 (500)\n",
      "2018-12-10 22:01:12 - x_train_vec - type: <class 'numpy.ndarray'>, shape:(1500, 6000)\n",
      "2018-12-10 22:01:13 - x_test_vec - type: <class 'numpy.ndarray'>, shape:(500, 6000)\n",
      "2018-12-10 22:01:13 ------------------------------------------------------------------------\n",
      "2018-12-10 22:01:13 - Build Model:\n",
      "2018-12-10 22:01:13 - MODEL 1:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 100)               600100    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 600,201\n",
      "Trainable params: 600,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "2018-12-10 22:01:13 - None\n",
      "2018-12-10 22:01:13 ------------------------------------------------------------------------\n",
      "2018-12-10 22:01:13 - Fit:\n",
      "Train on 450 samples, validate on 1050 samples\n",
      "Epoch 1/200\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.6925 - binary_accuracy: 0.5156 - val_loss: 0.6894 - val_binary_accuracy: 0.6486\n",
      "Epoch 2/200\n",
      "450/450 [==============================] - 0s 307us/step - loss: 0.6759 - binary_accuracy: 0.8667 - val_loss: 0.6855 - val_binary_accuracy: 0.7067\n",
      "Epoch 3/200\n",
      "450/450 [==============================] - 0s 276us/step - loss: 0.6594 - binary_accuracy: 0.9356 - val_loss: 0.6800 - val_binary_accuracy: 0.7248\n",
      "Epoch 4/200\n",
      "450/450 [==============================] - 0s 280us/step - loss: 0.6408 - binary_accuracy: 0.9578 - val_loss: 0.6731 - val_binary_accuracy: 0.7343\n",
      "Epoch 5/200\n",
      "450/450 [==============================] - 0s 274us/step - loss: 0.6175 - binary_accuracy: 0.9667 - val_loss: 0.6651 - val_binary_accuracy: 0.7438\n",
      "Epoch 6/200\n",
      "450/450 [==============================] - 0s 278us/step - loss: 0.5956 - binary_accuracy: 0.9711 - val_loss: 0.6566 - val_binary_accuracy: 0.7552\n",
      "Epoch 7/200\n",
      "450/450 [==============================] - 0s 275us/step - loss: 0.5718 - binary_accuracy: 0.9756 - val_loss: 0.6480 - val_binary_accuracy: 0.7686\n",
      "Epoch 8/200\n",
      "450/450 [==============================] - 0s 278us/step - loss: 0.5461 - binary_accuracy: 0.9756 - val_loss: 0.6393 - val_binary_accuracy: 0.7724\n",
      "Epoch 9/200\n",
      "450/450 [==============================] - 0s 277us/step - loss: 0.5217 - binary_accuracy: 0.9822 - val_loss: 0.6304 - val_binary_accuracy: 0.7762\n",
      "Epoch 10/200\n",
      "450/450 [==============================] - 0s 279us/step - loss: 0.4956 - binary_accuracy: 0.9778 - val_loss: 0.6215 - val_binary_accuracy: 0.7714\n",
      "Epoch 11/200\n",
      "450/450 [==============================] - 0s 275us/step - loss: 0.4657 - binary_accuracy: 0.9867 - val_loss: 0.6124 - val_binary_accuracy: 0.7695\n",
      "Epoch 12/200\n",
      "450/450 [==============================] - 0s 278us/step - loss: 0.4399 - binary_accuracy: 0.9844 - val_loss: 0.6036 - val_binary_accuracy: 0.7714\n",
      "Epoch 13/200\n",
      "450/450 [==============================] - 0s 278us/step - loss: 0.4168 - binary_accuracy: 0.9911 - val_loss: 0.5950 - val_binary_accuracy: 0.7714\n",
      "Epoch 14/200\n",
      "450/450 [==============================] - 0s 279us/step - loss: 0.3910 - binary_accuracy: 0.9956 - val_loss: 0.5866 - val_binary_accuracy: 0.7724\n",
      "Epoch 15/200\n",
      "450/450 [==============================] - 0s 283us/step - loss: 0.3639 - binary_accuracy: 0.9956 - val_loss: 0.5784 - val_binary_accuracy: 0.7695\n",
      "Epoch 16/200\n",
      "450/450 [==============================] - 0s 278us/step - loss: 0.3471 - binary_accuracy: 0.9889 - val_loss: 0.5704 - val_binary_accuracy: 0.7686\n",
      "Epoch 17/200\n",
      "450/450 [==============================] - 0s 276us/step - loss: 0.3215 - binary_accuracy: 0.9911 - val_loss: 0.5628 - val_binary_accuracy: 0.7695\n",
      "Epoch 18/200\n",
      "450/450 [==============================] - 0s 276us/step - loss: 0.3003 - binary_accuracy: 0.9956 - val_loss: 0.5555 - val_binary_accuracy: 0.7705\n",
      "Epoch 19/200\n",
      "450/450 [==============================] - 0s 275us/step - loss: 0.2841 - binary_accuracy: 0.9978 - val_loss: 0.5486 - val_binary_accuracy: 0.7705\n",
      "Epoch 20/200\n",
      "450/450 [==============================] - 0s 274us/step - loss: 0.2638 - binary_accuracy: 0.9956 - val_loss: 0.5420 - val_binary_accuracy: 0.7705\n",
      "Epoch 21/200\n",
      "450/450 [==============================] - 0s 278us/step - loss: 0.2433 - binary_accuracy: 0.9956 - val_loss: 0.5358 - val_binary_accuracy: 0.7714\n",
      "Epoch 22/200\n",
      "450/450 [==============================] - 0s 276us/step - loss: 0.2228 - binary_accuracy: 0.9956 - val_loss: 0.5300 - val_binary_accuracy: 0.7714\n",
      "Epoch 23/200\n",
      "450/450 [==============================] - 0s 307us/step - loss: 0.2163 - binary_accuracy: 0.9978 - val_loss: 0.5246 - val_binary_accuracy: 0.7714\n",
      "Epoch 24/200\n",
      "450/450 [==============================] - 0s 303us/step - loss: 0.2025 - binary_accuracy: 0.9933 - val_loss: 0.5195 - val_binary_accuracy: 0.7714\n",
      "Epoch 25/200\n",
      "450/450 [==============================] - 0s 284us/step - loss: 0.1837 - binary_accuracy: 0.9978 - val_loss: 0.5147 - val_binary_accuracy: 0.7686\n",
      "Epoch 26/200\n",
      "450/450 [==============================] - 0s 286us/step - loss: 0.1676 - binary_accuracy: 0.9978 - val_loss: 0.5103 - val_binary_accuracy: 0.7686\n",
      "Epoch 27/200\n",
      "450/450 [==============================] - 0s 276us/step - loss: 0.1582 - binary_accuracy: 0.9978 - val_loss: 0.5062 - val_binary_accuracy: 0.7676\n",
      "Epoch 28/200\n",
      "450/450 [==============================] - 0s 279us/step - loss: 0.1542 - binary_accuracy: 0.9978 - val_loss: 0.5025 - val_binary_accuracy: 0.7657\n",
      "Epoch 29/200\n",
      "450/450 [==============================] - 0s 274us/step - loss: 0.1397 - binary_accuracy: 0.9978 - val_loss: 0.4990 - val_binary_accuracy: 0.7676\n",
      "Epoch 30/200\n",
      "450/450 [==============================] - 0s 302us/step - loss: 0.1329 - binary_accuracy: 1.0000 - val_loss: 0.4958 - val_binary_accuracy: 0.7695\n",
      "Epoch 31/200\n",
      "450/450 [==============================] - 0s 288us/step - loss: 0.1265 - binary_accuracy: 1.0000 - val_loss: 0.4928 - val_binary_accuracy: 0.7705\n",
      "Epoch 32/200\n",
      "450/450 [==============================] - 0s 295us/step - loss: 0.1162 - binary_accuracy: 0.9978 - val_loss: 0.4900 - val_binary_accuracy: 0.7705\n",
      "Epoch 33/200\n",
      "450/450 [==============================] - 0s 292us/step - loss: 0.1058 - binary_accuracy: 1.0000 - val_loss: 0.4875 - val_binary_accuracy: 0.7714\n",
      "Epoch 34/200\n",
      "450/450 [==============================] - 0s 306us/step - loss: 0.0995 - binary_accuracy: 1.0000 - val_loss: 0.4852 - val_binary_accuracy: 0.7724\n",
      "Epoch 35/200\n",
      "450/450 [==============================] - 0s 300us/step - loss: 0.0980 - binary_accuracy: 1.0000 - val_loss: 0.4831 - val_binary_accuracy: 0.7714\n",
      "Epoch 36/200\n",
      "450/450 [==============================] - 0s 294us/step - loss: 0.0902 - binary_accuracy: 1.0000 - val_loss: 0.4812 - val_binary_accuracy: 0.7724\n",
      "Epoch 37/200\n",
      "450/450 [==============================] - 0s 299us/step - loss: 0.0870 - binary_accuracy: 1.0000 - val_loss: 0.4795 - val_binary_accuracy: 0.7724\n",
      "Epoch 38/200\n",
      "450/450 [==============================] - 0s 294us/step - loss: 0.0832 - binary_accuracy: 1.0000 - val_loss: 0.4779 - val_binary_accuracy: 0.7724\n",
      "Epoch 39/200\n",
      "450/450 [==============================] - 0s 292us/step - loss: 0.0775 - binary_accuracy: 1.0000 - val_loss: 0.4765 - val_binary_accuracy: 0.7714\n",
      "Epoch 40/200\n",
      "450/450 [==============================] - 0s 281us/step - loss: 0.0735 - binary_accuracy: 1.0000 - val_loss: 0.4752 - val_binary_accuracy: 0.7714\n",
      "Epoch 41/200\n",
      "450/450 [==============================] - 0s 280us/step - loss: 0.0663 - binary_accuracy: 1.0000 - val_loss: 0.4740 - val_binary_accuracy: 0.7733\n",
      "Epoch 42/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450/450 [==============================] - 0s 280us/step - loss: 0.0658 - binary_accuracy: 1.0000 - val_loss: 0.4729 - val_binary_accuracy: 0.7743\n",
      "Epoch 43/200\n",
      "450/450 [==============================] - 0s 279us/step - loss: 0.0599 - binary_accuracy: 1.0000 - val_loss: 0.4719 - val_binary_accuracy: 0.7714\n",
      "Epoch 44/200\n",
      "450/450 [==============================] - 0s 278us/step - loss: 0.0592 - binary_accuracy: 1.0000 - val_loss: 0.4710 - val_binary_accuracy: 0.7705\n",
      "Epoch 45/200\n",
      "450/450 [==============================] - 0s 278us/step - loss: 0.0537 - binary_accuracy: 1.0000 - val_loss: 0.4701 - val_binary_accuracy: 0.7686\n",
      "Epoch 46/200\n",
      "450/450 [==============================] - 0s 276us/step - loss: 0.0518 - binary_accuracy: 1.0000 - val_loss: 0.4694 - val_binary_accuracy: 0.7686\n",
      "Epoch 47/200\n",
      "450/450 [==============================] - 0s 274us/step - loss: 0.0507 - binary_accuracy: 1.0000 - val_loss: 0.4687 - val_binary_accuracy: 0.7695\n",
      "Epoch 48/200\n",
      "450/450 [==============================] - 0s 276us/step - loss: 0.0483 - binary_accuracy: 1.0000 - val_loss: 0.4681 - val_binary_accuracy: 0.7695\n",
      "Epoch 49/200\n",
      "450/450 [==============================] - 0s 274us/step - loss: 0.0461 - binary_accuracy: 1.0000 - val_loss: 0.4676 - val_binary_accuracy: 0.7695\n",
      "Epoch 50/200\n",
      "450/450 [==============================] - 0s 276us/step - loss: 0.0427 - binary_accuracy: 1.0000 - val_loss: 0.4672 - val_binary_accuracy: 0.7686\n",
      "Epoch 51/200\n",
      "450/450 [==============================] - 0s 276us/step - loss: 0.0418 - binary_accuracy: 1.0000 - val_loss: 0.4668 - val_binary_accuracy: 0.7686\n",
      "Epoch 52/200\n",
      "450/450 [==============================] - 0s 277us/step - loss: 0.0385 - binary_accuracy: 1.0000 - val_loss: 0.4664 - val_binary_accuracy: 0.7686\n",
      "Epoch 53/200\n",
      "450/450 [==============================] - 0s 274us/step - loss: 0.0362 - binary_accuracy: 1.0000 - val_loss: 0.4661 - val_binary_accuracy: 0.7676\n",
      "Epoch 54/200\n",
      "450/450 [==============================] - 0s 276us/step - loss: 0.0377 - binary_accuracy: 1.0000 - val_loss: 0.4658 - val_binary_accuracy: 0.7667\n",
      "Epoch 55/200\n",
      "450/450 [==============================] - 0s 277us/step - loss: 0.0365 - binary_accuracy: 1.0000 - val_loss: 0.4656 - val_binary_accuracy: 0.7676\n",
      "Epoch 56/200\n",
      "450/450 [==============================] - 0s 275us/step - loss: 0.0330 - binary_accuracy: 1.0000 - val_loss: 0.4654 - val_binary_accuracy: 0.7676\n",
      "Epoch 57/200\n",
      "450/450 [==============================] - 0s 277us/step - loss: 0.0335 - binary_accuracy: 1.0000 - val_loss: 0.4652 - val_binary_accuracy: 0.7676\n",
      "Epoch 58/200\n",
      "450/450 [==============================] - 0s 277us/step - loss: 0.0317 - binary_accuracy: 1.0000 - val_loss: 0.4651 - val_binary_accuracy: 0.7676\n",
      "Epoch 59/200\n",
      "450/450 [==============================] - 0s 277us/step - loss: 0.0311 - binary_accuracy: 1.0000 - val_loss: 0.4650 - val_binary_accuracy: 0.7676\n",
      "Epoch 60/200\n",
      "450/450 [==============================] - 0s 275us/step - loss: 0.0292 - binary_accuracy: 1.0000 - val_loss: 0.4650 - val_binary_accuracy: 0.7667\n",
      "Epoch 61/200\n",
      "450/450 [==============================] - 0s 278us/step - loss: 0.0300 - binary_accuracy: 1.0000 - val_loss: 0.4650 - val_binary_accuracy: 0.7676\n",
      "Epoch 62/200\n",
      "450/450 [==============================] - 0s 275us/step - loss: 0.0267 - binary_accuracy: 1.0000 - val_loss: 0.4650 - val_binary_accuracy: 0.7676\n",
      "Epoch 63/200\n",
      "450/450 [==============================] - 0s 278us/step - loss: 0.0281 - binary_accuracy: 1.0000 - val_loss: 0.4650 - val_binary_accuracy: 0.7676\n",
      "Epoch 64/200\n",
      "450/450 [==============================] - 0s 276us/step - loss: 0.0266 - binary_accuracy: 1.0000 - val_loss: 0.4651 - val_binary_accuracy: 0.7686\n",
      "Epoch 65/200\n",
      "450/450 [==============================] - 0s 278us/step - loss: 0.0251 - binary_accuracy: 1.0000 - val_loss: 0.4653 - val_binary_accuracy: 0.7667\n",
      "Epoch 66/200\n",
      "450/450 [==============================] - 0s 273us/step - loss: 0.0238 - binary_accuracy: 1.0000 - val_loss: 0.4654 - val_binary_accuracy: 0.7667\n",
      "Epoch 67/200\n",
      "450/450 [==============================] - 0s 278us/step - loss: 0.0241 - binary_accuracy: 1.0000 - val_loss: 0.4655 - val_binary_accuracy: 0.7667\n",
      "Epoch 68/200\n",
      "450/450 [==============================] - 0s 276us/step - loss: 0.0229 - binary_accuracy: 1.0000 - val_loss: 0.4656 - val_binary_accuracy: 0.7667\n",
      "Epoch 69/200\n",
      "450/450 [==============================] - 0s 276us/step - loss: 0.0208 - binary_accuracy: 1.0000 - val_loss: 0.4658 - val_binary_accuracy: 0.7667\n",
      "Epoch 70/200\n",
      "450/450 [==============================] - 0s 276us/step - loss: 0.0219 - binary_accuracy: 1.0000 - val_loss: 0.4660 - val_binary_accuracy: 0.7667\n",
      "Epoch 71/200\n",
      "450/450 [==============================] - 0s 277us/step - loss: 0.0203 - binary_accuracy: 1.0000 - val_loss: 0.4662 - val_binary_accuracy: 0.7667\n",
      "Epoch 72/200\n",
      "450/450 [==============================] - 0s 277us/step - loss: 0.0206 - binary_accuracy: 1.0000 - val_loss: 0.4664 - val_binary_accuracy: 0.7667\n",
      "Epoch 73/200\n",
      "450/450 [==============================] - 0s 278us/step - loss: 0.0197 - binary_accuracy: 1.0000 - val_loss: 0.4665 - val_binary_accuracy: 0.7676\n",
      "Epoch 74/200\n",
      "450/450 [==============================] - 0s 280us/step - loss: 0.0195 - binary_accuracy: 1.0000 - val_loss: 0.4666 - val_binary_accuracy: 0.7686\n",
      "Epoch 75/200\n",
      "450/450 [==============================] - 0s 279us/step - loss: 0.0178 - binary_accuracy: 1.0000 - val_loss: 0.4668 - val_binary_accuracy: 0.7695\n",
      "Epoch 76/200\n",
      "450/450 [==============================] - 0s 277us/step - loss: 0.0177 - binary_accuracy: 1.0000 - val_loss: 0.4670 - val_binary_accuracy: 0.7695\n",
      "Epoch 77/200\n",
      "450/450 [==============================] - 0s 283us/step - loss: 0.0183 - binary_accuracy: 1.0000 - val_loss: 0.4672 - val_binary_accuracy: 0.7695\n",
      "Epoch 78/200\n",
      "450/450 [==============================] - 0s 276us/step - loss: 0.0169 - binary_accuracy: 1.0000 - val_loss: 0.4675 - val_binary_accuracy: 0.7686\n",
      "Epoch 79/200\n",
      "450/450 [==============================] - 0s 278us/step - loss: 0.0169 - binary_accuracy: 1.0000 - val_loss: 0.4678 - val_binary_accuracy: 0.7676\n",
      "Epoch 80/200\n",
      "450/450 [==============================] - 0s 278us/step - loss: 0.0158 - binary_accuracy: 1.0000 - val_loss: 0.4681 - val_binary_accuracy: 0.7676\n",
      "Epoch 81/200\n",
      "450/450 [==============================] - 0s 276us/step - loss: 0.0160 - binary_accuracy: 1.0000 - val_loss: 0.4683 - val_binary_accuracy: 0.7676\n",
      "Epoch 82/200\n",
      "450/450 [==============================] - 0s 275us/step - loss: 0.0148 - binary_accuracy: 1.0000 - val_loss: 0.4686 - val_binary_accuracy: 0.7676\n",
      "Epoch 83/200\n",
      "450/450 [==============================] - 0s 277us/step - loss: 0.0135 - binary_accuracy: 1.0000 - val_loss: 0.4688 - val_binary_accuracy: 0.7686\n",
      "Epoch 84/200\n",
      "450/450 [==============================] - 0s 276us/step - loss: 0.0141 - binary_accuracy: 1.0000 - val_loss: 0.4690 - val_binary_accuracy: 0.7686\n",
      "Epoch 85/200\n",
      "450/450 [==============================] - 0s 279us/step - loss: 0.0144 - binary_accuracy: 1.0000 - val_loss: 0.4692 - val_binary_accuracy: 0.7686\n",
      "Epoch 86/200\n",
      "450/450 [==============================] - 0s 280us/step - loss: 0.0132 - binary_accuracy: 1.0000 - val_loss: 0.4694 - val_binary_accuracy: 0.7686\n",
      "Epoch 87/200\n",
      "450/450 [==============================] - 0s 277us/step - loss: 0.0136 - binary_accuracy: 1.0000 - val_loss: 0.4697 - val_binary_accuracy: 0.7695\n",
      "Epoch 88/200\n",
      "450/450 [==============================] - 0s 277us/step - loss: 0.0135 - binary_accuracy: 1.0000 - val_loss: 0.4699 - val_binary_accuracy: 0.7695\n",
      "Epoch 89/200\n",
      "450/450 [==============================] - 0s 288us/step - loss: 0.0141 - binary_accuracy: 1.0000 - val_loss: 0.4701 - val_binary_accuracy: 0.7686\n",
      "Epoch 90/200\n",
      "450/450 [==============================] - 0s 276us/step - loss: 0.0135 - binary_accuracy: 1.0000 - val_loss: 0.4704 - val_binary_accuracy: 0.7686\n",
      "Epoch 91/200\n",
      "450/450 [==============================] - 0s 277us/step - loss: 0.0118 - binary_accuracy: 1.0000 - val_loss: 0.4707 - val_binary_accuracy: 0.7686\n",
      "Epoch 92/200\n",
      "450/450 [==============================] - 0s 276us/step - loss: 0.0122 - binary_accuracy: 1.0000 - val_loss: 0.4710 - val_binary_accuracy: 0.7695\n",
      "Epoch 93/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450/450 [==============================] - 0s 276us/step - loss: 0.0123 - binary_accuracy: 1.0000 - val_loss: 0.4712 - val_binary_accuracy: 0.7695\n",
      "Epoch 94/200\n",
      "450/450 [==============================] - 0s 277us/step - loss: 0.0117 - binary_accuracy: 1.0000 - val_loss: 0.4715 - val_binary_accuracy: 0.7695\n",
      "Epoch 95/200\n",
      "450/450 [==============================] - 0s 275us/step - loss: 0.0116 - binary_accuracy: 1.0000 - val_loss: 0.4718 - val_binary_accuracy: 0.7695\n",
      "Epoch 96/200\n",
      "450/450 [==============================] - 0s 276us/step - loss: 0.0109 - binary_accuracy: 1.0000 - val_loss: 0.4721 - val_binary_accuracy: 0.7695\n",
      "Epoch 97/200\n",
      "450/450 [==============================] - 0s 274us/step - loss: 0.0104 - binary_accuracy: 1.0000 - val_loss: 0.4725 - val_binary_accuracy: 0.7686\n",
      "Epoch 98/200\n",
      "450/450 [==============================] - 0s 276us/step - loss: 0.0109 - binary_accuracy: 1.0000 - val_loss: 0.4728 - val_binary_accuracy: 0.7686\n",
      "Epoch 99/200\n",
      "450/450 [==============================] - 0s 275us/step - loss: 0.0105 - binary_accuracy: 1.0000 - val_loss: 0.4731 - val_binary_accuracy: 0.7686\n",
      "Epoch 100/200\n",
      "450/450 [==============================] - 0s 278us/step - loss: 0.0099 - binary_accuracy: 1.0000 - val_loss: 0.4734 - val_binary_accuracy: 0.7686\n",
      "Epoch 101/200\n",
      "450/450 [==============================] - 0s 277us/step - loss: 0.0106 - binary_accuracy: 1.0000 - val_loss: 0.4737 - val_binary_accuracy: 0.7686\n",
      "Epoch 102/200\n",
      "450/450 [==============================] - 0s 276us/step - loss: 0.0094 - binary_accuracy: 1.0000 - val_loss: 0.4740 - val_binary_accuracy: 0.7686\n",
      "Epoch 103/200\n",
      "450/450 [==============================] - 0s 276us/step - loss: 0.0098 - binary_accuracy: 1.0000 - val_loss: 0.4743 - val_binary_accuracy: 0.7686\n",
      "Epoch 104/200\n",
      "450/450 [==============================] - 0s 278us/step - loss: 0.0098 - binary_accuracy: 1.0000 - val_loss: 0.4745 - val_binary_accuracy: 0.7686\n",
      "Epoch 105/200\n",
      "450/450 [==============================] - 0s 274us/step - loss: 0.0092 - binary_accuracy: 1.0000 - val_loss: 0.4748 - val_binary_accuracy: 0.7686\n",
      "Epoch 106/200\n",
      "450/450 [==============================] - 0s 276us/step - loss: 0.0087 - binary_accuracy: 1.0000 - val_loss: 0.4751 - val_binary_accuracy: 0.7686\n",
      "Epoch 107/200\n",
      "450/450 [==============================] - 0s 275us/step - loss: 0.0086 - binary_accuracy: 1.0000 - val_loss: 0.4755 - val_binary_accuracy: 0.7686\n",
      "Epoch 108/200\n",
      "450/450 [==============================] - 0s 273us/step - loss: 0.0091 - binary_accuracy: 1.0000 - val_loss: 0.4758 - val_binary_accuracy: 0.7686\n",
      "Epoch 109/200\n",
      "450/450 [==============================] - 0s 278us/step - loss: 0.0092 - binary_accuracy: 1.0000 - val_loss: 0.4761 - val_binary_accuracy: 0.7695\n",
      "Epoch 110/200\n",
      "450/450 [==============================] - 0s 277us/step - loss: 0.0080 - binary_accuracy: 1.0000 - val_loss: 0.4765 - val_binary_accuracy: 0.7695\n",
      "Epoch 111/200\n",
      "450/450 [==============================] - 0s 276us/step - loss: 0.0087 - binary_accuracy: 1.0000 - val_loss: 0.4768 - val_binary_accuracy: 0.7686\n",
      "Epoch 112/200\n",
      "450/450 [==============================] - 0s 277us/step - loss: 0.0081 - binary_accuracy: 1.0000 - val_loss: 0.4772 - val_binary_accuracy: 0.7686\n",
      "Epoch 113/200\n",
      "450/450 [==============================] - 0s 275us/step - loss: 0.0082 - binary_accuracy: 1.0000 - val_loss: 0.4776 - val_binary_accuracy: 0.7695\n",
      "Epoch 114/200\n",
      "450/450 [==============================] - 0s 276us/step - loss: 0.0076 - binary_accuracy: 1.0000 - val_loss: 0.4779 - val_binary_accuracy: 0.7695\n",
      "Epoch 115/200\n",
      "450/450 [==============================] - 0s 276us/step - loss: 0.0080 - binary_accuracy: 1.0000 - val_loss: 0.4783 - val_binary_accuracy: 0.7695\n",
      "Epoch 116/200\n",
      "450/450 [==============================] - 0s 278us/step - loss: 0.0081 - binary_accuracy: 1.0000 - val_loss: 0.4787 - val_binary_accuracy: 0.7686\n",
      "Epoch 117/200\n",
      "450/450 [==============================] - 0s 299us/step - loss: 0.0077 - binary_accuracy: 1.0000 - val_loss: 0.4790 - val_binary_accuracy: 0.7686\n",
      "Epoch 118/200\n",
      "450/450 [==============================] - 0s 278us/step - loss: 0.0078 - binary_accuracy: 1.0000 - val_loss: 0.4794 - val_binary_accuracy: 0.7686\n",
      "Epoch 119/200\n",
      "450/450 [==============================] - 0s 272us/step - loss: 0.0072 - binary_accuracy: 1.0000 - val_loss: 0.4797 - val_binary_accuracy: 0.7686\n",
      "Epoch 120/200\n",
      "450/450 [==============================] - 0s 278us/step - loss: 0.0069 - binary_accuracy: 1.0000 - val_loss: 0.4800 - val_binary_accuracy: 0.7686\n",
      "Epoch 121/200\n",
      "450/450 [==============================] - 0s 274us/step - loss: 0.0071 - binary_accuracy: 1.0000 - val_loss: 0.4803 - val_binary_accuracy: 0.7695\n",
      "Epoch 122/200\n",
      "450/450 [==============================] - 0s 275us/step - loss: 0.0067 - binary_accuracy: 1.0000 - val_loss: 0.4806 - val_binary_accuracy: 0.7686\n",
      "Epoch 123/200\n",
      "450/450 [==============================] - 0s 277us/step - loss: 0.0069 - binary_accuracy: 1.0000 - val_loss: 0.4809 - val_binary_accuracy: 0.7686\n",
      "Epoch 124/200\n",
      "450/450 [==============================] - 0s 276us/step - loss: 0.0065 - binary_accuracy: 1.0000 - val_loss: 0.4812 - val_binary_accuracy: 0.7686\n",
      "Epoch 125/200\n",
      "450/450 [==============================] - 0s 280us/step - loss: 0.0069 - binary_accuracy: 1.0000 - val_loss: 0.4815 - val_binary_accuracy: 0.7686\n",
      "Epoch 126/200\n",
      "450/450 [==============================] - 0s 275us/step - loss: 0.0069 - binary_accuracy: 1.0000 - val_loss: 0.4818 - val_binary_accuracy: 0.7686\n",
      "Epoch 127/200\n",
      "450/450 [==============================] - 0s 274us/step - loss: 0.0060 - binary_accuracy: 1.0000 - val_loss: 0.4822 - val_binary_accuracy: 0.7686\n",
      "Epoch 128/200\n",
      "450/450 [==============================] - 0s 279us/step - loss: 0.0064 - binary_accuracy: 1.0000 - val_loss: 0.4825 - val_binary_accuracy: 0.7686\n",
      "Epoch 129/200\n",
      "450/450 [==============================] - 0s 276us/step - loss: 0.0064 - binary_accuracy: 1.0000 - val_loss: 0.4829 - val_binary_accuracy: 0.7686\n",
      "Epoch 130/200\n",
      "450/450 [==============================] - 0s 277us/step - loss: 0.0060 - binary_accuracy: 1.0000 - val_loss: 0.4832 - val_binary_accuracy: 0.7686\n",
      "Epoch 131/200\n",
      "450/450 [==============================] - 0s 275us/step - loss: 0.0062 - binary_accuracy: 1.0000 - val_loss: 0.4836 - val_binary_accuracy: 0.7676\n",
      "Epoch 132/200\n",
      "450/450 [==============================] - 0s 278us/step - loss: 0.0061 - binary_accuracy: 1.0000 - val_loss: 0.4840 - val_binary_accuracy: 0.7676\n",
      "Epoch 133/200\n",
      "450/450 [==============================] - 0s 275us/step - loss: 0.0060 - binary_accuracy: 1.0000 - val_loss: 0.4843 - val_binary_accuracy: 0.7676\n",
      "Epoch 134/200\n",
      "450/450 [==============================] - 0s 275us/step - loss: 0.0056 - binary_accuracy: 1.0000 - val_loss: 0.4846 - val_binary_accuracy: 0.7686\n",
      "Epoch 135/200\n",
      "450/450 [==============================] - 0s 275us/step - loss: 0.0057 - binary_accuracy: 1.0000 - val_loss: 0.4849 - val_binary_accuracy: 0.7686\n",
      "Epoch 136/200\n",
      "450/450 [==============================] - 0s 278us/step - loss: 0.0059 - binary_accuracy: 1.0000 - val_loss: 0.4852 - val_binary_accuracy: 0.7686\n",
      "Epoch 137/200\n",
      "450/450 [==============================] - 0s 275us/step - loss: 0.0056 - binary_accuracy: 1.0000 - val_loss: 0.4854 - val_binary_accuracy: 0.7714\n",
      "Epoch 138/200\n",
      "450/450 [==============================] - 0s 277us/step - loss: 0.0055 - binary_accuracy: 1.0000 - val_loss: 0.4857 - val_binary_accuracy: 0.7705\n",
      "Epoch 139/200\n",
      "450/450 [==============================] - 0s 275us/step - loss: 0.0054 - binary_accuracy: 1.0000 - val_loss: 0.4860 - val_binary_accuracy: 0.7695\n",
      "Epoch 140/200\n",
      "450/450 [==============================] - 0s 279us/step - loss: 0.0053 - binary_accuracy: 1.0000 - val_loss: 0.4863 - val_binary_accuracy: 0.7695\n",
      "Epoch 141/200\n",
      "450/450 [==============================] - 0s 278us/step - loss: 0.0052 - binary_accuracy: 1.0000 - val_loss: 0.4866 - val_binary_accuracy: 0.7705\n",
      "Epoch 142/200\n",
      "450/450 [==============================] - 0s 279us/step - loss: 0.0053 - binary_accuracy: 1.0000 - val_loss: 0.4869 - val_binary_accuracy: 0.7695\n",
      "Epoch 143/200\n",
      "450/450 [==============================] - 0s 277us/step - loss: 0.0055 - binary_accuracy: 1.0000 - val_loss: 0.4872 - val_binary_accuracy: 0.7695\n",
      "Epoch 144/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450/450 [==============================] - 0s 278us/step - loss: 0.0055 - binary_accuracy: 1.0000 - val_loss: 0.4876 - val_binary_accuracy: 0.7695\n",
      "Epoch 145/200\n",
      "450/450 [==============================] - 0s 279us/step - loss: 0.0052 - binary_accuracy: 1.0000 - val_loss: 0.4879 - val_binary_accuracy: 0.7695\n",
      "Epoch 146/200\n",
      "450/450 [==============================] - 0s 322us/step - loss: 0.0051 - binary_accuracy: 1.0000 - val_loss: 0.4883 - val_binary_accuracy: 0.7705\n",
      "Epoch 147/200\n",
      "450/450 [==============================] - 0s 458us/step - loss: 0.0048 - binary_accuracy: 1.0000 - val_loss: 0.4886 - val_binary_accuracy: 0.7705\n",
      "Epoch 148/200\n",
      "450/450 [==============================] - 0s 396us/step - loss: 0.0047 - binary_accuracy: 1.0000 - val_loss: 0.4890 - val_binary_accuracy: 0.7705\n",
      "Epoch 149/200\n",
      "450/450 [==============================] - 0s 398us/step - loss: 0.0046 - binary_accuracy: 1.0000 - val_loss: 0.4893 - val_binary_accuracy: 0.7695\n",
      "Epoch 150/200\n",
      "450/450 [==============================] - 0s 443us/step - loss: 0.0047 - binary_accuracy: 1.0000 - val_loss: 0.4896 - val_binary_accuracy: 0.7705\n",
      "Epoch 151/200\n",
      "450/450 [==============================] - 0s 423us/step - loss: 0.0039 - binary_accuracy: 1.0000 - val_loss: 0.4899 - val_binary_accuracy: 0.7705\n",
      "Epoch 152/200\n",
      "450/450 [==============================] - 0s 400us/step - loss: 0.0047 - binary_accuracy: 1.0000 - val_loss: 0.4902 - val_binary_accuracy: 0.7705\n",
      "Epoch 153/200\n",
      "450/450 [==============================] - 0s 389us/step - loss: 0.0044 - binary_accuracy: 1.0000 - val_loss: 0.4905 - val_binary_accuracy: 0.7705\n",
      "Epoch 154/200\n",
      "450/450 [==============================] - 0s 388us/step - loss: 0.0040 - binary_accuracy: 1.0000 - val_loss: 0.4908 - val_binary_accuracy: 0.7705\n",
      "Epoch 155/200\n",
      "450/450 [==============================] - 0s 328us/step - loss: 0.0041 - binary_accuracy: 1.0000 - val_loss: 0.4911 - val_binary_accuracy: 0.7705\n",
      "Epoch 156/200\n",
      "450/450 [==============================] - 0s 294us/step - loss: 0.0040 - binary_accuracy: 1.0000 - val_loss: 0.4914 - val_binary_accuracy: 0.7695\n",
      "Epoch 157/200\n",
      "450/450 [==============================] - 0s 460us/step - loss: 0.0040 - binary_accuracy: 1.0000 - val_loss: 0.4918 - val_binary_accuracy: 0.7705\n",
      "Epoch 158/200\n",
      "450/450 [==============================] - 0s 424us/step - loss: 0.0042 - binary_accuracy: 1.0000 - val_loss: 0.4921 - val_binary_accuracy: 0.7705\n",
      "Epoch 159/200\n",
      "450/450 [==============================] - 0s 369us/step - loss: 0.0043 - binary_accuracy: 1.0000 - val_loss: 0.4923 - val_binary_accuracy: 0.7705\n",
      "Epoch 160/200\n",
      "450/450 [==============================] - 0s 402us/step - loss: 0.0044 - binary_accuracy: 1.0000 - val_loss: 0.4926 - val_binary_accuracy: 0.7705\n",
      "Epoch 161/200\n",
      "450/450 [==============================] - 0s 401us/step - loss: 0.0042 - binary_accuracy: 1.0000 - val_loss: 0.4928 - val_binary_accuracy: 0.7705\n",
      "Epoch 162/200\n",
      "450/450 [==============================] - 0s 456us/step - loss: 0.0044 - binary_accuracy: 1.0000 - val_loss: 0.4931 - val_binary_accuracy: 0.7695\n",
      "Epoch 163/200\n",
      "450/450 [==============================] - 0s 326us/step - loss: 0.0042 - binary_accuracy: 1.0000 - val_loss: 0.4934 - val_binary_accuracy: 0.7705\n",
      "Epoch 164/200\n",
      "450/450 [==============================] - 0s 289us/step - loss: 0.0042 - binary_accuracy: 1.0000 - val_loss: 0.4936 - val_binary_accuracy: 0.7705\n",
      "Epoch 165/200\n",
      "450/450 [==============================] - 0s 338us/step - loss: 0.0036 - binary_accuracy: 1.0000 - val_loss: 0.4939 - val_binary_accuracy: 0.7705\n",
      "Epoch 166/200\n",
      "450/450 [==============================] - 0s 433us/step - loss: 0.0039 - binary_accuracy: 1.0000 - val_loss: 0.4942 - val_binary_accuracy: 0.7705\n",
      "Epoch 167/200\n",
      "450/450 [==============================] - 0s 411us/step - loss: 0.0040 - binary_accuracy: 1.0000 - val_loss: 0.4945 - val_binary_accuracy: 0.7705\n",
      "Epoch 168/200\n",
      "450/450 [==============================] - 0s 304us/step - loss: 0.0035 - binary_accuracy: 1.0000 - val_loss: 0.4948 - val_binary_accuracy: 0.7705\n",
      "Epoch 169/200\n",
      "450/450 [==============================] - 0s 338us/step - loss: 0.0040 - binary_accuracy: 1.0000 - val_loss: 0.4951 - val_binary_accuracy: 0.7705\n",
      "Epoch 170/200\n",
      "450/450 [==============================] - 0s 384us/step - loss: 0.0038 - binary_accuracy: 1.0000 - val_loss: 0.4955 - val_binary_accuracy: 0.7705\n",
      "Epoch 171/200\n",
      "450/450 [==============================] - 0s 426us/step - loss: 0.0038 - binary_accuracy: 1.0000 - val_loss: 0.4958 - val_binary_accuracy: 0.7705\n",
      "Epoch 172/200\n",
      "450/450 [==============================] - 0s 373us/step - loss: 0.0037 - binary_accuracy: 1.0000 - val_loss: 0.4961 - val_binary_accuracy: 0.7705\n",
      "Epoch 173/200\n",
      "450/450 [==============================] - 0s 433us/step - loss: 0.0036 - binary_accuracy: 1.0000 - val_loss: 0.4964 - val_binary_accuracy: 0.7705\n",
      "Epoch 174/200\n",
      "450/450 [==============================] - 0s 329us/step - loss: 0.0034 - binary_accuracy: 1.0000 - val_loss: 0.4967 - val_binary_accuracy: 0.7705\n",
      "Epoch 175/200\n",
      "450/450 [==============================] - 0s 286us/step - loss: 0.0031 - binary_accuracy: 1.0000 - val_loss: 0.4970 - val_binary_accuracy: 0.7695\n",
      "Epoch 176/200\n",
      "450/450 [==============================] - 0s 325us/step - loss: 0.0032 - binary_accuracy: 1.0000 - val_loss: 0.4973 - val_binary_accuracy: 0.7695\n",
      "Epoch 177/200\n",
      "450/450 [==============================] - 0s 434us/step - loss: 0.0036 - binary_accuracy: 1.0000 - val_loss: 0.4976 - val_binary_accuracy: 0.7695\n",
      "Epoch 178/200\n",
      "450/450 [==============================] - 0s 373us/step - loss: 0.0034 - binary_accuracy: 1.0000 - val_loss: 0.4979 - val_binary_accuracy: 0.7695\n",
      "Epoch 179/200\n",
      "450/450 [==============================] - 0s 449us/step - loss: 0.0034 - binary_accuracy: 1.0000 - val_loss: 0.4981 - val_binary_accuracy: 0.7686\n",
      "Epoch 180/200\n",
      "450/450 [==============================] - 0s 337us/step - loss: 0.0035 - binary_accuracy: 1.0000 - val_loss: 0.4984 - val_binary_accuracy: 0.7695\n",
      "Epoch 181/200\n",
      "450/450 [==============================] - 0s 287us/step - loss: 0.0035 - binary_accuracy: 1.0000 - val_loss: 0.4987 - val_binary_accuracy: 0.7695\n",
      "Epoch 182/200\n",
      "450/450 [==============================] - 0s 463us/step - loss: 0.0030 - binary_accuracy: 1.0000 - val_loss: 0.4991 - val_binary_accuracy: 0.7695\n",
      "Epoch 183/200\n",
      "450/450 [==============================] - 0s 391us/step - loss: 0.0033 - binary_accuracy: 1.0000 - val_loss: 0.4994 - val_binary_accuracy: 0.7695\n",
      "Epoch 184/200\n",
      "450/450 [==============================] - 0s 432us/step - loss: 0.0034 - binary_accuracy: 1.0000 - val_loss: 0.4997 - val_binary_accuracy: 0.7695\n",
      "Epoch 185/200\n",
      "450/450 [==============================] - 0s 385us/step - loss: 0.0029 - binary_accuracy: 1.0000 - val_loss: 0.4999 - val_binary_accuracy: 0.7695\n",
      "Epoch 186/200\n",
      "450/450 [==============================] - 0s 364us/step - loss: 0.0029 - binary_accuracy: 1.0000 - val_loss: 0.5002 - val_binary_accuracy: 0.7695\n",
      "Epoch 187/200\n",
      "450/450 [==============================] - 0s 283us/step - loss: 0.0029 - binary_accuracy: 1.0000 - val_loss: 0.5005 - val_binary_accuracy: 0.7705\n",
      "Epoch 188/200\n",
      "450/450 [==============================] - 0s 286us/step - loss: 0.0030 - binary_accuracy: 1.0000 - val_loss: 0.5007 - val_binary_accuracy: 0.7705\n",
      "Epoch 189/200\n",
      "450/450 [==============================] - 0s 286us/step - loss: 0.0029 - binary_accuracy: 1.0000 - val_loss: 0.5010 - val_binary_accuracy: 0.7705\n",
      "Epoch 190/200\n",
      "450/450 [==============================] - 0s 281us/step - loss: 0.0029 - binary_accuracy: 1.0000 - val_loss: 0.5013 - val_binary_accuracy: 0.7705\n",
      "Epoch 191/200\n",
      "450/450 [==============================] - 0s 296us/step - loss: 0.0029 - binary_accuracy: 1.0000 - val_loss: 0.5016 - val_binary_accuracy: 0.7705\n",
      "Epoch 192/200\n",
      "450/450 [==============================] - 0s 443us/step - loss: 0.0030 - binary_accuracy: 1.0000 - val_loss: 0.5018 - val_binary_accuracy: 0.7695\n",
      "Epoch 193/200\n",
      "450/450 [==============================] - 0s 345us/step - loss: 0.0030 - binary_accuracy: 1.0000 - val_loss: 0.5021 - val_binary_accuracy: 0.7695\n",
      "Epoch 194/200\n",
      "450/450 [==============================] - 0s 279us/step - loss: 0.0030 - binary_accuracy: 1.0000 - val_loss: 0.5024 - val_binary_accuracy: 0.7695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 195/200\n",
      "450/450 [==============================] - 0s 285us/step - loss: 0.0031 - binary_accuracy: 1.0000 - val_loss: 0.5027 - val_binary_accuracy: 0.7695\n",
      "Epoch 196/200\n",
      "450/450 [==============================] - 0s 378us/step - loss: 0.0026 - binary_accuracy: 1.0000 - val_loss: 0.5030 - val_binary_accuracy: 0.7695\n",
      "Epoch 197/200\n",
      "450/450 [==============================] - 0s 454us/step - loss: 0.0026 - binary_accuracy: 1.0000 - val_loss: 0.5033 - val_binary_accuracy: 0.7695\n",
      "Epoch 198/200\n",
      "450/450 [==============================] - 0s 290us/step - loss: 0.0028 - binary_accuracy: 1.0000 - val_loss: 0.5036 - val_binary_accuracy: 0.7695\n",
      "Epoch 199/200\n",
      "450/450 [==============================] - 0s 374us/step - loss: 0.0026 - binary_accuracy: 1.0000 - val_loss: 0.5039 - val_binary_accuracy: 0.7714\n",
      "Epoch 200/200\n",
      "450/450 [==============================] - 0s 419us/step - loss: 0.0028 - binary_accuracy: 1.0000 - val_loss: 0.5042 - val_binary_accuracy: 0.7714\n",
      "2018-12-10 22:01:42 ------------------------------------------------------------------------\n",
      "2018-12-10 22:01:42 - Predictions:\n",
      "500/500 [==============================] - 0s 287us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32)]'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-10 22:01:42 ------------------------------------------------------------------------\n",
      "2018-12-10 22:01:42 - Test:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0]'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-10 22:01:42 ------------------------------------------------------------------------\n",
      "2018-12-10 22:01:42 - Performance:\n",
      "500/500 [==============================] - 0s 169us/step\n",
      "2018-12-10 22:01:42 - [score, accuracy]\n",
      "2018-12-10 22:01:42 - [0.4475015070438385, 0.7999999990463257]\n",
      "2018-12-10 22:01:42 ------------------------------------------------------------------------\n",
      "2018-12-10 22:01:42 - Saving parameters: results/parameters/parameters_20181210220044_acc_0.800000.csv\n",
      "2018-12-10 22:01:43 ------------------------------------------------------------------------\n",
      "2018-12-10 22:01:43 - Saving predictions: results/predictions/predictions_20181210220044_acc_0.800000.csv\n",
      "2018-12-10 22:01:43 - Done.\n",
      "2018-12-10 22:01:43 ------------------------------------------------------------------------\n",
      "2018-12-10 22:01:43 - STOP.\n",
      "2018-12-10 22:01:43 ------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Cargamos argumentos de prueba\n",
    "arguments = ['--model=1',\n",
    "             '--max_features=6000',\n",
    "             '--num_units=100',\n",
    "             '--dropout=0.5',\n",
    "             '--batch_size=200',             \n",
    "             '--epochs=200',\n",
    "             '--shuffle=batch',\n",
    "             '--random_seed=10',\n",
    "             '--verbose=1'\n",
    "            ]\n",
    "\n",
    "\"\"\"\n",
    "arguments = ['--model=1',\n",
    "             '--max_features=4000',\n",
    "             '--num_units=1',\n",
    "             '--dropout=0.5',\n",
    "             '--batch_size=200',             \n",
    "             '--epochs=70',\n",
    "             '--shuffle=batch',\n",
    "             '--random_seed=10',\n",
    "             '--verbose=1'\n",
    "            ]\n",
    "\"\"\"\n",
    "\n",
    "# Ejecutamos el procedimiento principal\n",
    "main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-22T04:10:46.640400Z",
     "start_time": "2018-09-22T04:09:09.824815Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Cargamos argumentos de prueba\n",
    "arguments = ['--model=2',\n",
    "             '--max_features=6000',\n",
    "             '--num_units=3000',\n",
    "             '--dropout=0.2',\n",
    "             '--batch_size=200',             \n",
    "             '--epochs=30',\n",
    "             '--shuffle=batch',\n",
    "             '--random_seed=10',\n",
    "             '--verbose=1'\n",
    "            ]\n",
    "\n",
    "# Ejecutamos el procedimiento principal\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos argumentos de prueba\n",
    "arguments = ['--model=2',\n",
    "             '--max_features=6000',\n",
    "             '--num_units=300',\n",
    "             '--dropout=0.2',\n",
    "             '--batch_size=200',             \n",
    "             '--epochs=30',\n",
    "             '--shuffle=batch',\n",
    "             '--random_seed=10',\n",
    "             '--verbose=1'\n",
    "            ]\n",
    "\n",
    "# Ejecutamos el procedimiento principal\n",
    "main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Reporte \n",
    "\n",
    "__Responde al punto:__\n",
    "_Reportar los hyperparámetros y resultados de todos los modelos entrenados. Para esto, pueden utilizar una notebook o un archivo (pdf|md). Dentro de este reporte tiene que describir:_\n",
    "\n",
    "* _Hyperparámetros con los que procesaron el dataset: tamaño del vocabulario, normalizaciones, etc._\n",
    "* _Las decisiones tomadas al construir cada modelo: regularización, dropout, número y tamaño de las capas, optimizador._\n",
    "* _Proceso de entrenamiento: división del train/test, tamaño del batch, número de épocas, métricas de evaluación._ \n",
    "* _Seleccione los mejores hiperparámetros en función de su rendimiento. El proceso de entrenamiento debería ser el mismo\n",
    "para todos los modelos._\n",
    "* _(Punto estrella) Analizar si el clasificador está haciendo overfitting. Esto se puede determinar a partir del resultado del método fit._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Reporte de Hiperparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training samples 1500 (1500), test_samples 500 (500)\n",
    "2018-12-08 17:36:49 - x_train_vec - type: <class 'numpy.ndarray'>, shape:(1500, 35393)\n",
    "2018-12-08 17:36:50 - x_test_vec - type: <class 'numpy.ndarray'>, shape:(500, 22062)\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Descripción de los Modelos Utilizados\n",
    "\n",
    "Se describen a continuación los modelos utilizados para el trabajo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1. Descripción del Modelo 1\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2. Descripción del Modelo 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3. Descripción del Modelo 3\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.4. Descripción del Modelo 4\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Descripción de Proceso de Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. Selección de los mejores hiperparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5. Análisis sobre el Overfitting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_files('dataset/txt_sentoken', shuffle=False)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset.data, dataset.target, test_size=0.25, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(analyzer='word', use_idf=True, max_features=6000)\n",
    "    \n",
    "x_train_vec = vectorizer.fit_transform(X_train).toarray()\n",
    "    \n",
    "x_test_vec = vectorizer.fit_transform(X_test).toarray()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "def print_eval(model, X, y_true):\n",
    "    y_pred = model.predict(X)\n",
    "    acc = metrics.accuracy_score(y_true, y_pred)\n",
    "    print('accuracy\\t{:2.2f}\\n'.format(acc))\n",
    "    print(metrics.classification_report(y_true, y_pred, target_names=['neg', 'pos']))\n",
    "    cm = metrics.confusion_matrix(y_true, y_pred)\n",
    "    print(cm)\n",
    "\n",
    "\n",
    "def eval(model, X, y_true):\n",
    "    y_pred = model.predict(X)\n",
    "    acc = metrics.accuracy_score(y_true, y_pred)\n",
    "    f1 = metrics.f1_score(y_true, y_pred, average='macro')\n",
    "    return {'acc': acc, 'f1': f1}\n",
    "\n",
    "\n",
    "def print_short_eval(model, X, y_true):\n",
    "    res = eval(model, X, y_true)\n",
    "    print('accuracy\\t{acc:2.6f}\\tmacro f1\\t{f1:2.6f}'.format(**res))\n",
    "    return res\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "pipeline = Pipeline([\n",
    "    #('vect', TfidfVectorizer(binary=False, max_df=0.1, min_df=5, ngram_range=(1, 4))),\n",
    "    ('vect', TfidfVectorizer(analyzer='word', use_idf=True, max_features=6000)),\n",
    "    ('clf', LogisticRegression(C=1, random_state=0, tol=0.001))\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "print_short_eval(pipeline, X_train, y_train)\n",
    "print_short_eval(pipeline, X_test, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vect = TfidfVectorizer(binary=True)\n",
    "\n",
    "#vect = CountVectorizer(binary=True)\n",
    "pipeline = Pipeline([\n",
    "    ('vect', vect),\n",
    "    ('clf', LinearSVC(random_state=0)),\n",
    "])\n",
    "pipeline.fit(X_train, y_train)\n",
    "print_eval(pipeline, X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
